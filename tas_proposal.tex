% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate-05-2015}
\usepackage[numbers]{natbib}
\usepackage{amsfonts}
\usepackage{tabularx}
\usepackage{color}
\newcommand{\abc}[1]{{\color{red} #1}}
\usepackage{amsmath}

\begin{document}

\conferenceinfo{}{June 2016}


%
% --- Author Metadata here ---
% \conferenceinfo{}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{A Proposal for a Question--Answer Selection Model}
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{Alberto Barr\'on-Cede\~no}
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.


\maketitle
\begin{abstract}
\end{abstract}

%%%%%
% One of the features our product offers is "macro suggestions". That is, we 
% suggest the most suitable answers to an unanswered question, out of a set of 
% templated responses/answers (macros). In order to build our model, we look at 
% the previous history of tickets (questions & answers that a customer service 
% team has received and solved) and look for previous answers that are similar to 
% any of the templated responses we have.
% 
% There are a few situations to consider for this problem:
% - First of all, a reply doesn't necessarily belong to any templated answer 
% class.
% - In other cases, only part of the reply will contain a templated response.
% - Finally, very often a templated response will have been used but slightly 
% modified to suit the question, the tone of the conversation or the users' 
% data better.
% 
% a) Given a set of templated responses (macros) and an answer chosen from a 
% ticket at random, describe a method that determines whether this answer belongs 
% to or is based on one of the templated responses, and if that's the case 
% classifies it into the right macro.
% 
% Now that we are able to find and put into a certain class the questions that 
% trigger a macro response, we can build our macro classifier for suggesting 
% macros to new unanswered questions.
% 
% b) Assuming you have a dataset of questions, where each one is labelled with the 
% macro class it belongs to, describe one method you would explore to create a 
% classifier that can label new, previously unseen questions. Also, don't forget 
% to explain how you'd engineer the features used to learn your classifier.
% 
% Note: We can assume the training set has between 1,000 and 100,000 instances, 
% and between 10 and 1000 classes.

%%%%%

%
%  Use this command to print the description
%
%\printccsdesc

% We no longer use \terms command
%\terms{Theory}
%\vspace{-1em}
%\keywords{Community Question Answering; Learning to Rank, Syntactic Structures}


\section{Introduction}
\label{sec:intro}


% \section{Related Work}
\section{Problem Description} 
% \label{sec:taskdescription}


\subsection{Problem Constraints}

In the problem of suggesting answers out of a pool of question--answer pairs, a 
few constraints must be considered:

\begin{itemize}
\item 
\end{itemize}





\section{Model(s) to Classify Answers}
\label{sec:l2r}


\section{Model(s) to Classify Questions}
% b) Assuming you have a dataset of questions, where each one is labelled with
% the macro class it belongs to, describe one method you would explore to create 
% a classifier that can label new, previously unseen questions. Also, don't 
% forget to explain how you'd engineer the features used to learn your 
% classifier.
Problem ``b'' can be formally defined as follows. Let $q\in c_i$ be a 
previously observed question that belongs to macro-class $c_i$%
\footnote{What exactly means macro-class (opposite to a simple class) 
should be discussed.}
Let $Q$ be a collection of questions, each of which belongs to class $c\in 
C_I$. Build a classifier which predicts the most likely class of a new 
question $q_n$. That is, this problems falls into the classical 
multi-class scenario. Multiple machine learning models exist to approach this 
kind of problem, ranging from simple decision trees to more sophisticated 
convolutional models.%
\footnote{Maybe remove this ``fancy'' convolutional terms}
The distribution of the classes is currently unknown, which causes the 
selection of the best model difficult. For instance, if there was a dominant 
class, that is, a class with a highly representative amount of instances in the 
training set, even a decision tree could be considered, as this kind of model 
do well with imbalanced datasets. Still, the first option seems to be to apply 
a multi-class support vector machine (SVM)\abc{add reference}; for instance, 
in the form of an ensemble of binary classifiers. That is, $I$ binary SVMs are 
built, one per class, and the predicted class becomes the one with the 
maximum score among all the classifiers. 

It is worth noting that this is not posed as a paraphrasing problem. That is, 
the task is not determining whether $q_i$ and $q_j$ are similar to each 
other. Instead, the task consists of determining whether the new question $q$ 
belongs to the same macro-class as a set of questions $Q$. As a result, it 
is not unreasonable to approach the problem with models such as $k$ nearest 
neighbors. Of course, before opting for such a model, it would be necessary 
to prove before hand if a characterisation is at hand which actually causes 
the instances that belong to the same class to fall close within the vector 
space. 

\subsection{Preliminary Feature Engineering}

Going back to the differentiation between the proposed task and paraphrasing, 
if this task was the latter, the core of the features would be composed of a 
manifold of similarities at lexical, syntactic, and semantic level. Of course, 
in our case such similarities would still play an important role in the 
inference ---if $q_1$ belongs to class $i$ and $sim(q_1,q_2)\rightarrow 1$, it 
is very likely that both questions belong to the same class. 

Another bunch of features I would consider would consist of the so called 
explicit semantic analysis (ESA)\abc{add reference}. In summary, ESA takes 
advantage of a large reference corpus, usually containing a maniforold of 
encyclopedic articles. ESA represents a text as a vector in which each dimension 
is activated by the similarity between the text and the article contents. As a 
result, identifying the topics covered in a question might represent valuable 
information to determine if it belongs to a given macro-class. Obviously, ESA 
could be computed both at question and at word label. In the later case, the 
representation vector slice would consists of average over all the words in $q$.

Another subset of features would be vocabulary-based. With statistical weighting 
models such as the well known $tf$-$idf$, I would identify the likelihood of a 
given keyword of belonging to given class. In a clustering-like fashion, we can 
identify the keywords with the highest and lowest association levels to each of 
the classes. A selection of the most discriminating keywords would be considered 
as binary features: whether keyword $k$ appears or not in the question. 

% the keywords gain, it seems like in this 
% case we are more interested in the subject, in the topic of the class. 
% Therefore, in principle I would opt for ass or which be definition of tven a set 
% of questions $Q$ belonging to  represents 
% Both the answer and question identification problems can be defined as a ranking 
% task. Given a new question $q$, retrieve the most similar (relevant) question 
% (answer) from a pool of previously existing uly exosn the case of 

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
% \appendix
% %Appendix A
% \section{Headings in Appendices}
% The sig-alternate.cls file itself is chock-full of succinct
% and helpful comments.  If you consider yourself a moderately
% experienced to expert user of \LaTeX, you may find reading
% it useful but please remember not to change it.
% %\balancecolumns % GM June 2007
% % That's all folks!
\end{document}


